# r_alternative.py - —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –æ–±—ã—á–Ω–æ–≥–æ Trainer
#Qwen2.5-1.5B-Instruct
import torch
from transformers import (
    AutoModelForCausalLM, AutoTokenizer,
    TrainingArguments, Trainer, DataCollatorForLanguageModeling
)
from peft import LoraConfig, get_peft_model, TaskType
from datasets import load_from_disk
import os
os.environ['TRANSFORMERS_AWQ_BACKEND'] = 'autoawq'

BASE_MODEL_PATH = "/home/chelovek/work/model4b_8bit_config"
DATASET_PATH = "/home/chelovek/work/lora_project/datasets/my_dataset/"
OUTPUT_DIR = "/home/chelovek/work/lora_project/models/lora_adapters23"

# config LoRA
lora_config = LoraConfig(
    #—Ç–æ–ª—â–∏–Ω–∞ —á–µ–º –±–æ–ª—å—à–µ —Ç–µ–º –±–æ–ª—å—à–µ –≤–ª–∏—è–µ—Ç –Ω–∞ –∫–æ–Ω–µ—á–Ω—ã–µ –≤–µ—Å–∞
    r=4,
    #–°–ò–õ–ê –í–õ–ò–Ø–ù–ò–Ø
    lora_alpha=6,
    # —Å–ª–æ–∏ —Ç—É—Ç –Ω–∞–¥–æ —Ä–∞–∑–∂–µ–≤–∞—Ç—å –º–Ω–µ qkw —ç—Ç–æ –ø–æ–Ω—è—Ç–Ω–æ —ç—Ç–æ –º–∞—Ç—Ä–∏—Ü—ã –≤–Ω–∏–º–∞–Ω–∏—è –∞ —á–µ —Ç–∫–æ–µ "gate_proj", "up_proj", "down_proj" —è –≤–∞—â–µ –Ω–µ –µ–±—É –∞–∞–∞–∞–∞ 
    #—è –ø–æ–Ω —ç—Ç gate_proj —Ä–µ—à–∞–µ—Ç —á–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å Up - "—Ä–∞—Å—à–∏—Ä—è–µ—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ" own_proj - —Å–∂–∏–º–∞–µ—Ç, –Ω—É —Ç–∏–ø–∏—á–Ω—ã–π —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä))) 
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"],
    #–Ω—É –¥—Ä–æ–ø–∞—É—Ç
    lora_dropout=0.05,
    # —Ç–∏–ø–æ –Ω–µ —Ç—Ä–æ–≥–∞–µ–º –±–∏–∞—Å
    bias="none",
    #–∫–∞–∑—É–∞–ª—å–Ω–∞—è –º–∞—Å–∫–∞ –ø–æ —Ç–∏–ø—É –∑–∞–¥–∞—á–∏
    task_type=TaskType.CAUSAL_LM,
)


print("this model download")
model = AutoModelForCausalLM.from_pretrained(
    BASE_MODEL_PATH,
    torch_dtype=torch.float16,
    device_map="auto",
    trust_remote_code=True,
)

tokenizer = AutoTokenizer.from_pretrained(
    BASE_MODEL_PATH,
    trust_remote_code=True
)

if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token

# using Lora
model = get_peft_model(model, lora_config)
model.print_trainable_parameters()


def tokenize_function(examples):
    return tokenizer(
        examples["text"],
        truncation=True,
        padding="max_length",
        max_length=128,
    )

print("dowload model and tokeni.")
dataset = load_from_disk(DATASET_PATH)

# tokenization
# create map token
tokenized_train = dataset["train"].map(
    tokenize_function,
    batched=True,
    remove_columns=dataset["train"].column_names
)
#test kit dataset
tokenized_test = dataset["test"].map(
    tokenize_function,
    batched=True,
    remove_columns=dataset["test"].column_names
)

# this config lern model
training_args = TrainingArguments(
    output_dir=OUTPUT_DIR,
    num_train_epochs=2,
    per_device_train_batch_size=4,
    per_device_eval_batch_size=1,
    #–≤ –ø–µ—Ä–≤—ã–π —Ä–∞–∑ –ø—Ä–æ–±—É—é —ç—Ç–æ—Ç —Ö–∞–∫, —á—É—Ç—å –ø–æ–∑–∂–µ –ø–æ—Å–º–æ—Ç—Ä—é –ª—É—á—à–µ –∏–ª–∏ –∫–∞–∫
    gradient_accumulation_steps=12,
    #–∞–¥–∞–ø—Ç–∏–≤–Ω–æ –ø–æ–¥–¥—Ä–∞—á–∏–≤–∞–µ—Ç lr  –ü–õ–ê–í–ù–´–ô –°–¢–ê–†–¢ –ü–µ—Ä–≤—ã–µ 10 —à–∞–≥–æ–≤ lr –æ—Ç 0 –¥–æ 2e-4
    warmup_steps=10,
    logging_steps=10,
    save_steps=10,
    eval_strategy="steps",
    eval_steps=10,
    learning_rate=2e-4,
    fp16=True,
    optim="adamw_torch",
    #—Ç–æ–∂–µ –≤–ø–µ—Ä–≤—ã–µ –ø—Ä–æ–±—É—é - –í–º–µ—Å—Ç–æ —Ö—Ä–∞–Ω–µ–Ω–∏—è –í–°–ï–• –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∏—Ö –Ω–∞ –ª–µ—Ç—É –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ
    gradient_checkpointing=True,
    report_to="none",
    save_total_limit=2,
)

# Data collator
data_collator = DataCollatorForLanguageModeling(
    tokenizer=tokenizer,
    mlm=False,
)

# 8. –°–û–ó–î–ê–ù–ò–ï –¢–†–ï–ù–ï–†–ê
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_train,
    eval_dataset=tokenized_test,
    data_collator=data_collator,
)

print("=" * 60)
print("üéØ –°–¢–ê–†–¢ –û–ë–£–ß–ï–ù–ò–Ø LoRA")
print(f"üìä –†–∞–∑–º–µ—Ä —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞: {len(tokenized_train)}")
print(f"üìä –†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞: {len(tokenized_test)}")
print(f"‚öôÔ∏è  –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è:")
print(f"   - –≠–ø–æ—Ö–∏: {training_args.num_train_epochs}")
print(f"   - Learning rate: {training_args.learning_rate}")
print(f"   - Batch size: {training_args.per_device_train_batch_size}")
print(f"   - Gradient accumulation: {training_args.gradient_accumulation_steps}")
print(f"   - –î–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: 256 —Ç–æ–∫–µ–Ω–æ–≤")
print("=" * 60)


# 9. –û–ë–£–ß–ï–ù–ò–ï
print("–°—Ç–∞—Ä—Ç –æ–±—É—á–µ–Ω–∏—è...")
trainer.train()


# 10. –°–û–•–†–ê–ù–ï–ù–ò–ï
model.save_pretrained(OUTPUT_DIR)
tokenizer.save_pretrained(OUTPUT_DIR)


print(f"–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {OUTPUT_DIR}")